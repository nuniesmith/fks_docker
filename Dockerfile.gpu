# GPU Base Image for FKS Services
# This image contains PyTorch and training libraries that are shared across GPU services:
# - PyTorch (torch, torchvision, torchaudio)
# - Transformers (transformers, accelerate)
# - Training libraries (datasets, wandb, mlflow, tensorboard)
# - Reinforcement learning (stable-baselines3, gymnasium)
# - Model monitoring (alibi-detect)
# - Scientific computing (scikit-learn, scipy, matplotlib, seaborn, optuna)
#
# Usage:
#   docker build -t nuniesmith/fks:docker-gpu -f Dockerfile.gpu .
#   docker push nuniesmith/fks:docker-gpu
#
# Then GPU services can use: FROM nuniesmith/fks:docker-gpu AS builder

FROM nuniesmith/fks:docker-ml AS gpu-base

WORKDIR /app

# Install PyTorch and transformers
# These are large packages that take time to build, so we pre-install them in the base image
RUN --mount=type=cache,target=/root/.cache/pip \
    python -m pip install --no-cache-dir \
    "torch==2.8.0" \
    "torchvision==0.23.0" \
    "torchaudio==2.8.0" \
    "transformers==4.56.0" \
    "accelerate==1.10.1" \
    "datasets==4.0.0" \
    "wandb==0.21.2" \
    "mlflow==3.3.2" \
    "tensorboard==2.20.0" \
    "stable-baselines3>=2.2.0" \
    "gymnasium>=0.29.1,<1.3.0" \
    "alibi-detect>=0.11.0" \
    "scikit-learn==1.7.1" \
    "scipy>=1.11.0" \
    "matplotlib==3.10.6" \
    "seaborn==0.13.2" \
    "optuna==4.5.0" \
    "pandas==2.3.2"

# Verify installations
RUN python -c "import torch; import transformers; import mlflow; import wandb; print('✅ GPU packages installed successfully')" || echo "⚠️  Some GPU packages may not be available"

# Label the image
LABEL maintainer="nuniesmith" \
    description="GPU base image with PyTorch, Transformers, and training libraries" \
    version="1.0.0" \
    base="nuniesmith/fks:docker-ml"
